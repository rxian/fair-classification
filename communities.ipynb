{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T02:27:22.874997Z",
     "iopub.status.busy": "2022-11-24T02:27:22.874117Z",
     "iopub.status.idle": "2022-11-24T02:27:24.107319Z",
     "shell.execute_reply": "2022-11-24T02:27:24.106667Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os, urllib.request\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn, sklearn.model_selection, sklearn.linear_model\n",
    "\n",
    "from projection_simplex_vectorized import projection_simplex\n",
    "import postprocess\n",
    "\n",
    "split_ratio_for_postprocessing = 0.5\n",
    "\n",
    "seed = 33\n",
    "rng = np.random.default_rng(seed)\n",
    "noise_fn = lambda shape: rng.laplace(loc=0.0, scale=0.2 / 5, size=shape)\n",
    "n_perturbations = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and pre-process UCI Communities and Crime dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T02:27:24.112678Z",
     "iopub.status.busy": "2022-11-24T02:27:24.112416Z",
     "iopub.status.idle": "2022-11-24T02:27:24.899226Z",
     "shell.execute_reply": "2022-11-24T02:27:24.898501Z"
    }
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"state\", \"county\", \"community\", \"communityname\", \"fold\", \"population\",\n",
    "    \"householdsize\", \"racepctblack\", \"racePctWhite\", \"racePctAsian\",\n",
    "    \"racePctHisp\", \"agePct12t21\", \"agePct12t29\", \"agePct16t24\", \"agePct65up\",\n",
    "    \"numbUrban\", \"pctUrban\", \"medIncome\", \"pctWWage\", \"pctWFarmSelf\",\n",
    "    \"pctWInvInc\", \"pctWSocSec\", \"pctWPubAsst\", \"pctWRetire\", \"medFamInc\",\n",
    "    \"perCapInc\", \"whitePerCap\", \"blackPerCap\", \"indianPerCap\", \"AsianPerCap\",\n",
    "    \"OtherPerCap\", \"HispPerCap\", \"NumUnderPov\", \"PctPopUnderPov\",\n",
    "    \"PctLess9thGrade\", \"PctNotHSGrad\", \"PctBSorMore\", \"PctUnemployed\",\n",
    "    \"PctEmploy\", \"PctEmplManu\", \"PctEmplProfServ\", \"PctOccupManu\",\n",
    "    \"PctOccupMgmtProf\", \"MalePctDivorce\", \"MalePctNevMarr\", \"FemalePctDiv\",\n",
    "    \"TotalPctDiv\", \"PersPerFam\", \"PctFam2Par\", \"PctKids2Par\",\n",
    "    \"PctYoungKids2Par\", \"PctTeen2Par\", \"PctWorkMomYoungKids\", \"PctWorkMom\",\n",
    "    \"NumIlleg\", \"PctIlleg\", \"NumImmig\", \"PctImmigRecent\", \"PctImmigRec5\",\n",
    "    \"PctImmigRec8\", \"PctImmigRec10\", \"PctRecentImmig\", \"PctRecImmig5\",\n",
    "    \"PctRecImmig8\", \"PctRecImmig10\", \"PctSpeakEnglOnly\", \"PctNotSpeakEnglWell\",\n",
    "    \"PctLargHouseFam\", \"PctLargHouseOccup\", \"PersPerOccupHous\",\n",
    "    \"PersPerOwnOccHous\", \"PersPerRentOccHous\", \"PctPersOwnOccup\",\n",
    "    \"PctPersDenseHous\", \"PctHousLess3BR\", \"MedNumBR\", \"HousVacant\",\n",
    "    \"PctHousOccup\", \"PctHousOwnOcc\", \"PctVacantBoarded\", \"PctVacMore6Mos\",\n",
    "    \"MedYrHousBuilt\", \"PctHousNoPhone\", \"PctWOFullPlumb\", \"OwnOccLowQuart\",\n",
    "    \"OwnOccMedVal\", \"OwnOccHiQuart\", \"RentLowQ\", \"RentMedian\", \"RentHighQ\",\n",
    "    \"MedRent\", \"MedRentPctHousInc\", \"MedOwnCostPctInc\", \"MedOwnCostPctIncNoMtg\",\n",
    "    \"NumInShelters\", \"NumStreet\", \"PctForeignBorn\", \"PctBornSameState\",\n",
    "    \"PctSameHouse85\", \"PctSameCity85\", \"PctSameState85\", \"LemasSwornFT\",\n",
    "    \"LemasSwFTPerPop\", \"LemasSwFTFieldOps\", \"LemasSwFTFieldPerPop\",\n",
    "    \"LemasTotalReq\", \"LemasTotReqPerPop\", \"PolicReqPerOffic\", \"PolicPerPop\",\n",
    "    \"RacialMatchCommPol\", \"PctPolicWhite\", \"PctPolicBlack\", \"PctPolicHisp\",\n",
    "    \"PctPolicAsian\", \"PctPolicMinor\", \"OfficAssgnDrugUnits\",\n",
    "    \"NumKindsDrugsSeiz\", \"PolicAveOTWorked\", \"LandArea\", \"PopDens\",\n",
    "    \"PctUsePubTrans\", \"PolicCars\", \"PolicOperBudg\", \"LemasPctPolicOnPatr\",\n",
    "    \"LemasGangUnitDeploy\", \"LemasPctOfficDrugUn\", \"PolicBudgPerPop\",\n",
    "    \"ViolentCrimesPerPop\"\n",
    "]\n",
    "\n",
    "data_path = \"data/communities/communities.data\"\n",
    "if not os.path.exists(data_path):\n",
    "  os.makedirs(\"data/communities\", exist_ok=True)\n",
    "  urllib.request.urlretrieve(\n",
    "      \"https://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data\",\n",
    "      data_path)\n",
    "\n",
    "original = pd.read_csv(data_path,\n",
    "                       names=features,\n",
    "                       sep=r\",\",\n",
    "                       engine=\"python\",\n",
    "                       na_values=\"?\")\n",
    "\n",
    "# Drop community name, state, and county, and columns with missing values\n",
    "original = original.drop([\"communityname\", \"state\", \"county\"],\n",
    "                         axis=1).dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T02:27:24.904397Z",
     "iopub.status.busy": "2022-11-24T02:27:24.904097Z",
     "iopub.status.idle": "2022-11-24T02:27:24.944480Z",
     "shell.execute_reply": "2022-11-24T02:27:24.943658Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_transform(df):\n",
    "  \"\"\"Normalize features.\"\"\"\n",
    "  binary_data = pd.get_dummies(df)\n",
    "  scaler = sklearn.preprocessing.StandardScaler()\n",
    "  data = pd.DataFrame(scaler.fit_transform(binary_data),\n",
    "                      columns=binary_data.columns)\n",
    "  data.index = df.index\n",
    "  return data\n",
    "\n",
    "\n",
    "# Create 5 equidistance bins for ViolentCrimesPerPop column\n",
    "labels_original = pd.cut(original[\"ViolentCrimesPerPop\"], 5)\n",
    "\n",
    "# Get sensitive attributes\n",
    "minority_pct = np.stack([\n",
    "    original[a].to_numpy()\n",
    "    for a in [\"racePctHisp\", \"racePctAsian\", \"racepctblack\"]\n",
    "],\n",
    "                        axis=1)\n",
    "minority_presence = np.array([\"hispanic\", \"asian\",\n",
    "                              \"black\"])[minority_pct.argmax(axis=1)]\n",
    "minority_presence[original[\"racePctWhite\"] > 0.95] = \"white\"\n",
    "original[\"MinorityPresence\"] = minority_presence\n",
    "\n",
    "label_names, labels = np.unique(labels_original, return_inverse=True)\n",
    "n_labels = len(label_names)\n",
    "\n",
    "data = original.copy()\n",
    "data = data.drop([\"ViolentCrimesPerPop\", \"fold\"], axis=1)\n",
    "data = data_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T02:27:24.947778Z",
     "iopub.status.busy": "2022-11-24T02:27:24.947500Z",
     "iopub.status.idle": "2022-11-24T02:27:24.957259Z",
     "shell.execute_reply": "2022-11-24T02:27:24.956504Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_group_labels_and_print_statistics(sensitive_attributes):\n",
    "\n",
    "  group_names, groups = np.unique(\n",
    "      original[sensitive_attributes].to_numpy().astype(str),\n",
    "      return_inverse=True,\n",
    "      axis=0)\n",
    "  n_groups = len(group_names)\n",
    "  print(\"Demographic groups:\",\n",
    "        ', '.join([\"'\" + ', '.join(n) + \"'\" for n in group_names]))\n",
    "\n",
    "  # Compute dataset statistics\n",
    "  df = original.copy()\n",
    "  df[\"Target\"] = labels_original\n",
    "  group_column = original[sensitive_attributes[0]]\n",
    "  for attribute in sensitive_attributes[1:]:\n",
    "    group_column = np.add(np.add(group_column, \", \"), original[attribute])\n",
    "  df[\"Group\"] = group_column\n",
    "  grouped = df.groupby([\"Target\", \"Group\"]).size().unstack()\n",
    "  n_labels = len(grouped.index)\n",
    "  n_groups = len(grouped.columns)\n",
    "  counts = grouped.sum(axis=0)\n",
    "  normalized = np.nan_to_num((grouped.to_numpy() / counts.to_numpy())).T\n",
    "  diff = np.abs(normalized[:, None, :] - normalized[None, :, :])\n",
    "  postprocessor = postprocess.PostProcessorDP()\n",
    "  postprocessor.fit(np.concatenate([np.eye(n_labels) for _ in range(n_groups)],\n",
    "                                   axis=0),\n",
    "                    np.repeat(np.arange(n_groups), n_labels),\n",
    "                    p=normalized.flatten())\n",
    "  res = {\n",
    "      \"balanced_accuracy\": {\n",
    "          \"perfect_postprocessed\": (n_groups - postprocessor.score_) / n_groups\n",
    "      },\n",
    "      \"dp_gap_linf_max\": {\n",
    "          \"perfect_predictor\": np.max(diff)\n",
    "      },\n",
    "      \"dp_gap_l1_max\": {\n",
    "          \"perfect_predictor\": np.max(1 / 2 * np.sum(diff, axis=2))\n",
    "      },\n",
    "      \"dp_gap_l1_avg\": {\n",
    "          \"perfect_predictor\":\n",
    "              np.mean(1 / 2 * np.sum(diff, axis=2)[np.triu_indices(n_groups, 1)]\n",
    "                     )\n",
    "      },\n",
    "  }\n",
    "\n",
    "  display(pd.DataFrame(res))\n",
    "  display(grouped / counts)\n",
    "  display(pd.DataFrame(counts, columns=[\"Count\"]).T)\n",
    "\n",
    "  return groups, n_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T02:27:24.959951Z",
     "iopub.status.busy": "2022-11-24T02:27:24.959692Z",
     "iopub.status.idle": "2022-11-24T02:27:25.145089Z",
     "shell.execute_reply": "2022-11-24T02:27:25.144445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic groups: 'asian', 'black', 'hispanic', 'white'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>dp_gap_linf_max</th>\n",
       "      <th>dp_gap_l1_max</th>\n",
       "      <th>dp_gap_l1_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>perfect_postprocessed</th>\n",
       "      <td>0.766781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perfect_predictor</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.581516</td>\n",
       "      <td>0.581516</td>\n",
       "      <td>0.363946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       balanced_accuracy  dp_gap_linf_max  dp_gap_l1_max  \\\n",
       "perfect_postprocessed           0.766781              NaN            NaN   \n",
       "perfect_predictor                    NaN         0.581516       0.581516   \n",
       "\n",
       "                       dp_gap_l1_avg  \n",
       "perfect_postprocessed            NaN  \n",
       "perfect_predictor           0.363946  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Group</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(-0.001, 0.2]</th>\n",
       "      <td>0.768683</td>\n",
       "      <td>0.340625</td>\n",
       "      <td>0.417323</td>\n",
       "      <td>0.922141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.2, 0.4]</th>\n",
       "      <td>0.156584</td>\n",
       "      <td>0.279687</td>\n",
       "      <td>0.367454</td>\n",
       "      <td>0.060827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.4, 0.6]</th>\n",
       "      <td>0.032028</td>\n",
       "      <td>0.185938</td>\n",
       "      <td>0.131234</td>\n",
       "      <td>0.012165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.6, 0.8]</th>\n",
       "      <td>0.028470</td>\n",
       "      <td>0.092188</td>\n",
       "      <td>0.049869</td>\n",
       "      <td>0.002433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.8, 1.0]</th>\n",
       "      <td>0.014235</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.034121</td>\n",
       "      <td>0.002433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Group             asian     black  hispanic     white\n",
       "Target                                               \n",
       "(-0.001, 0.2]  0.768683  0.340625  0.417323  0.922141\n",
       "(0.2, 0.4]     0.156584  0.279687  0.367454  0.060827\n",
       "(0.4, 0.6]     0.032028  0.185938  0.131234  0.012165\n",
       "(0.6, 0.8]     0.028470  0.092188  0.049869  0.002433\n",
       "(0.8, 1.0]     0.014235  0.101562  0.034121  0.002433"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Group</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count</th>\n",
       "      <td>562</td>\n",
       "      <td>640</td>\n",
       "      <td>381</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Group  asian  black  hispanic  white\n",
       "Count    562    640       381    411"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sensitive_attributes = [\"MinorityPresence\"]\n",
    "groups, n_groups = get_group_labels_and_print_statistics(sensitive_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T02:27:25.148045Z",
     "iopub.status.busy": "2022-11-24T02:27:25.147880Z",
     "iopub.status.idle": "2022-11-24T02:27:46.562631Z",
     "shell.execute_reply": "2022-11-24T02:27:46.562301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>dp_gap_linf_max</th>\n",
       "      <th>dp_gap_l1_max</th>\n",
       "      <th>dp_gap_l1_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf</th>\n",
       "      <td>0.661510</td>\n",
       "      <td>0.673644</td>\n",
       "      <td>0.532059</td>\n",
       "      <td>0.532059</td>\n",
       "      <td>0.338814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.659510</td>\n",
       "      <td>0.671309</td>\n",
       "      <td>0.519798</td>\n",
       "      <td>0.523049</td>\n",
       "      <td>0.335162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.48</th>\n",
       "      <td>0.659513</td>\n",
       "      <td>0.671617</td>\n",
       "      <td>0.504172</td>\n",
       "      <td>0.507423</td>\n",
       "      <td>0.327165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.45</th>\n",
       "      <td>0.660520</td>\n",
       "      <td>0.672465</td>\n",
       "      <td>0.485837</td>\n",
       "      <td>0.488383</td>\n",
       "      <td>0.312971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.42</th>\n",
       "      <td>0.660020</td>\n",
       "      <td>0.671431</td>\n",
       "      <td>0.459874</td>\n",
       "      <td>0.464203</td>\n",
       "      <td>0.296898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.656013</td>\n",
       "      <td>0.667856</td>\n",
       "      <td>0.435342</td>\n",
       "      <td>0.439671</td>\n",
       "      <td>0.282624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.38</th>\n",
       "      <td>0.655005</td>\n",
       "      <td>0.666605</td>\n",
       "      <td>0.416819</td>\n",
       "      <td>0.416994</td>\n",
       "      <td>0.268478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.35</th>\n",
       "      <td>0.651997</td>\n",
       "      <td>0.663411</td>\n",
       "      <td>0.388096</td>\n",
       "      <td>0.390421</td>\n",
       "      <td>0.254090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.32</th>\n",
       "      <td>0.649982</td>\n",
       "      <td>0.661559</td>\n",
       "      <td>0.364242</td>\n",
       "      <td>0.367569</td>\n",
       "      <td>0.241549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.645970</td>\n",
       "      <td>0.657761</td>\n",
       "      <td>0.339434</td>\n",
       "      <td>0.342761</td>\n",
       "      <td>0.227811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.28</th>\n",
       "      <td>0.646472</td>\n",
       "      <td>0.657419</td>\n",
       "      <td>0.324633</td>\n",
       "      <td>0.331639</td>\n",
       "      <td>0.220037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.639450</td>\n",
       "      <td>0.649758</td>\n",
       "      <td>0.294942</td>\n",
       "      <td>0.301730</td>\n",
       "      <td>0.203033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.22</th>\n",
       "      <td>0.638950</td>\n",
       "      <td>0.649416</td>\n",
       "      <td>0.274421</td>\n",
       "      <td>0.283302</td>\n",
       "      <td>0.188581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.633935</td>\n",
       "      <td>0.644199</td>\n",
       "      <td>0.266769</td>\n",
       "      <td>0.276618</td>\n",
       "      <td>0.182746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.18</th>\n",
       "      <td>0.631922</td>\n",
       "      <td>0.641957</td>\n",
       "      <td>0.235354</td>\n",
       "      <td>0.250395</td>\n",
       "      <td>0.165351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.15</th>\n",
       "      <td>0.629425</td>\n",
       "      <td>0.639420</td>\n",
       "      <td>0.218665</td>\n",
       "      <td>0.234987</td>\n",
       "      <td>0.156930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <td>0.626422</td>\n",
       "      <td>0.636812</td>\n",
       "      <td>0.194867</td>\n",
       "      <td>0.211627</td>\n",
       "      <td>0.139218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.621399</td>\n",
       "      <td>0.631503</td>\n",
       "      <td>0.172635</td>\n",
       "      <td>0.195120</td>\n",
       "      <td>0.127155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <td>0.616382</td>\n",
       "      <td>0.626562</td>\n",
       "      <td>0.146935</td>\n",
       "      <td>0.168605</td>\n",
       "      <td>0.113410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>0.610364</td>\n",
       "      <td>0.621377</td>\n",
       "      <td>0.129062</td>\n",
       "      <td>0.146028</td>\n",
       "      <td>0.098333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02</th>\n",
       "      <td>0.603347</td>\n",
       "      <td>0.613135</td>\n",
       "      <td>0.121810</td>\n",
       "      <td>0.137212</td>\n",
       "      <td>0.092889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.600332</td>\n",
       "      <td>0.610082</td>\n",
       "      <td>0.124433</td>\n",
       "      <td>0.140331</td>\n",
       "      <td>0.092426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.597317</td>\n",
       "      <td>0.607205</td>\n",
       "      <td>0.125330</td>\n",
       "      <td>0.140592</td>\n",
       "      <td>0.088431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy  balanced_accuracy  dp_gap_linf_max  dp_gap_l1_max  \\\n",
       "inf   0.661510           0.673644         0.532059       0.532059   \n",
       "0.5   0.659510           0.671309         0.519798       0.523049   \n",
       "0.48  0.659513           0.671617         0.504172       0.507423   \n",
       "0.45  0.660520           0.672465         0.485837       0.488383   \n",
       "0.42  0.660020           0.671431         0.459874       0.464203   \n",
       "0.4   0.656013           0.667856         0.435342       0.439671   \n",
       "0.38  0.655005           0.666605         0.416819       0.416994   \n",
       "0.35  0.651997           0.663411         0.388096       0.390421   \n",
       "0.32  0.649982           0.661559         0.364242       0.367569   \n",
       "0.3   0.645970           0.657761         0.339434       0.342761   \n",
       "0.28  0.646472           0.657419         0.324633       0.331639   \n",
       "0.25  0.639450           0.649758         0.294942       0.301730   \n",
       "0.22  0.638950           0.649416         0.274421       0.283302   \n",
       "0.2   0.633935           0.644199         0.266769       0.276618   \n",
       "0.18  0.631922           0.641957         0.235354       0.250395   \n",
       "0.15  0.629425           0.639420         0.218665       0.234987   \n",
       "0.12  0.626422           0.636812         0.194867       0.211627   \n",
       "0.1   0.621399           0.631503         0.172635       0.195120   \n",
       "0.08  0.616382           0.626562         0.146935       0.168605   \n",
       "0.05  0.610364           0.621377         0.129062       0.146028   \n",
       "0.02  0.603347           0.613135         0.121810       0.137212   \n",
       "0.01  0.600332           0.610082         0.124433       0.140331   \n",
       "0.0   0.597317           0.607205         0.125330       0.140592   \n",
       "\n",
       "      dp_gap_l1_avg  \n",
       "inf        0.338814  \n",
       "0.5        0.335162  \n",
       "0.48       0.327165  \n",
       "0.45       0.312971  \n",
       "0.42       0.296898  \n",
       "0.4        0.282624  \n",
       "0.38       0.268478  \n",
       "0.35       0.254090  \n",
       "0.32       0.241549  \n",
       "0.3        0.227811  \n",
       "0.28       0.220037  \n",
       "0.25       0.203033  \n",
       "0.22       0.188581  \n",
       "0.2        0.182746  \n",
       "0.18       0.165351  \n",
       "0.15       0.156930  \n",
       "0.12       0.139218  \n",
       "0.1        0.127155  \n",
       "0.08       0.113410  \n",
       "0.05       0.098333  \n",
       "0.02       0.092889  \n",
       "0.01       0.092426  \n",
       "0.0        0.088431  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps = [\n",
    "    0.5, 0.48, 0.45, 0.42, 0.4, 0.38, 0.35, 0.32, 0.3, 0.28, 0.25, 0.22, 0.2,\n",
    "    0.18, 0.15, 0.12, 0.1, 0.08, 0.05, 0.02, 0.01, 0.0\n",
    "]\n",
    "res = defaultdict(dict)\n",
    "\n",
    "for e in eps:\n",
    "\n",
    "  all_r = []\n",
    "\n",
    "  # print(\"Fold...\", end=\"\", flush=True)\n",
    "  for fold in original[\"fold\"].unique():\n",
    "    # print(f\"{fold} \", end=\"\", flush=True)\n",
    "\n",
    "    train_data = data[original[\"fold\"] != fold]\n",
    "    train_labels = labels[original[\"fold\"] != fold]\n",
    "    train_groups = groups[original[\"fold\"] != fold]\n",
    "    test_data = data[original[\"fold\"] == fold]\n",
    "    test_labels = labels[original[\"fold\"] == fold]\n",
    "    test_groups = groups[original[\"fold\"] == fold]\n",
    "\n",
    "    # Train data split\n",
    "    train_data_pre, train_data_post, train_labels_pre, train_labels_post, train_groups_pre, train_groups_post = sklearn.model_selection.train_test_split(\n",
    "        train_data,\n",
    "        train_labels,\n",
    "        train_groups,\n",
    "        test_size=split_ratio_for_postprocessing,\n",
    "        random_state=seed)\n",
    "\n",
    "    train_labels_pre_one_hot = pd.get_dummies(train_labels_pre)\n",
    "\n",
    "    predictor = sklearn.linear_model.LinearRegression()\n",
    "    predictor.fit(train_data_pre, train_labels_pre_one_hot)\n",
    "    predict_fn = lambda X: projection_simplex(predictor.predict(X), axis=1)\n",
    "    postprocessor = postprocess.postprocess(predict_fn,\n",
    "                                            train_data_post,\n",
    "                                            train_groups_post,\n",
    "                                            eps=e)\n",
    "    all_r.append(\n",
    "        postprocess.evaluate(predict_fn, postprocessor, test_data, test_labels,\n",
    "                             test_groups, n_labels, n_groups))\n",
    "    # print()\n",
    "\n",
    "  r = {\n",
    "      k1: {k2: np.mean([d[k1][k2] for d in all_r]) for k2 in all_r[0][k1]\n",
    "          } for k1, v1 in all_r[0].items()\n",
    "  }\n",
    "  for k, v in r.items():\n",
    "    res[k][\"inf\"] = v[\"predictor\"]\n",
    "    res[k][e] = v[\"postprocessor\"]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "ax.scatter(res[\"dp_gap_l1_max\"].values(),\n",
    "           res[\"balanced_accuracy\"].values(),\n",
    "           zorder=2)\n",
    "ax.set_xlabel(\"DP gap\")\n",
    "ax.set_ylabel(\"Balanced accuracy\")\n",
    "ax.set_title(\"Communities (race)\")\n",
    "ax.grid(True, which=\"both\", zorder=0)\n",
    "plt.show()\n",
    "display(pd.DataFrame(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T02:27:46.564586Z",
     "iopub.status.busy": "2022-11-24T02:27:46.564407Z",
     "iopub.status.idle": "2022-11-24T02:28:14.403447Z",
     "shell.execute_reply": "2022-11-24T02:28:14.402544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Laplace smoothing:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>dp_gap_linf_max</th>\n",
       "      <th>dp_gap_l1_max</th>\n",
       "      <th>dp_gap_l1_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf</th>\n",
       "      <td>0.661948</td>\n",
       "      <td>0.674289</td>\n",
       "      <td>0.532238</td>\n",
       "      <td>0.532238</td>\n",
       "      <td>0.340846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.598172</td>\n",
       "      <td>0.608269</td>\n",
       "      <td>0.108782</td>\n",
       "      <td>0.119111</td>\n",
       "      <td>0.074183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  balanced_accuracy  dp_gap_linf_max  dp_gap_l1_max  \\\n",
       "inf  0.661948           0.674289         0.532238       0.532238   \n",
       "0.0  0.598172           0.608269         0.108782       0.119111   \n",
       "\n",
       "     dp_gap_l1_avg  \n",
       "inf       0.340846  \n",
       "0.0       0.074183  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_r = []\n",
    "\n",
    "# print(\"Fold...\", end=\"\", flush=True)\n",
    "for fold in original[\"fold\"].unique():\n",
    "  # print(f\"{fold} \", end=\"\", flush=True)\n",
    "\n",
    "  train_data = data[original[\"fold\"] != fold]\n",
    "  train_labels = labels[original[\"fold\"] != fold]\n",
    "  train_groups = groups[original[\"fold\"] != fold]\n",
    "  test_data = data[original[\"fold\"] == fold]\n",
    "  test_labels = labels[original[\"fold\"] == fold]\n",
    "  test_groups = groups[original[\"fold\"] == fold]\n",
    "\n",
    "  # Train data split\n",
    "  train_data_pre, train_data_post, train_labels_pre, train_labels_post, train_groups_pre, train_groups_post = sklearn.model_selection.train_test_split(\n",
    "      train_data,\n",
    "      train_labels,\n",
    "      train_groups,\n",
    "      test_size=split_ratio_for_postprocessing,\n",
    "      random_state=seed)\n",
    "\n",
    "  train_labels_pre_one_hot = pd.get_dummies(train_labels_pre)\n",
    "\n",
    "  predictor = sklearn.linear_model.LinearRegression()\n",
    "  predictor.fit(train_data_pre, train_labels_pre_one_hot)\n",
    "  predict_fn = lambda X: projection_simplex(predictor.predict(X), axis=1)\n",
    "  postprocessor = postprocess.postprocess(predict_fn,\n",
    "                                          train_data_post,\n",
    "                                          train_groups_post,\n",
    "                                          noise_fn=noise_fn,\n",
    "                                          n_perturbations=n_perturbations)\n",
    "  all_r.append(\n",
    "      postprocess.evaluate(predict_fn,\n",
    "                           postprocessor,\n",
    "                           test_data,\n",
    "                           test_labels,\n",
    "                           test_groups,\n",
    "                           n_labels,\n",
    "                           n_groups,\n",
    "                           noise_fn=noise_fn,\n",
    "                           n_perturbations=1000))\n",
    "# print()\n",
    "\n",
    "r = {\n",
    "    k1: {k2: np.mean([d[k1][k2] for d in all_r]) for k2 in all_r[0][k1]\n",
    "        } for k1, v1 in all_r[0].items()\n",
    "}\n",
    "res = {\n",
    "    k: {\n",
    "        \"inf\": v[\"predictor\"],\n",
    "        0.0: v[\"postprocessor\"]\n",
    "    } for k, v in r.items()\n",
    "}\n",
    "print(\"With Laplace smoothing:\")\n",
    "display(pd.DataFrame(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "19e61f44fac9031dd94097741e1a6b3cb28108cf6746ab61e71bd478567bc8e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
